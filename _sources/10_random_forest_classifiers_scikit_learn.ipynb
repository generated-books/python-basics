{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Forest Classifiers in Scikit-learn\n",
        "\n",
        "This notebook introduces the concept of Random Forest classifiers and demonstrates how to implement them using scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, let's import the necessary libraries. We'll use scikit-learn for the Random Forest classifier and dataset, and matplotlib for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's create a synthetic dataset for classification. We'll use scikit-learn's make_classification function to generate this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "X, y = make_classification(n_samples=1000, n_features=4, n_informative=2, n_redundant=0, random_state=42)\n",
        "print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create an instance of the RandomForestClassifier. We'll set the number of trees (n_estimators) to 100 and use a random state for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "print(rf_classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll fit the Random Forest classifier on our dataset. This step trains the model on the provided data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "rf_classifier.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's make predictions on the same dataset to see how well our model performs. In practice, you'd use a separate test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "predictions = rf_classifier.predict(X)\n",
        "print(f\"First 10 predictions: {predictions[:10]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can evaluate the model's accuracy using the score method, which computes the mean accuracy on the given data and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "accuracy = rf_classifier.score(X, y)\n",
        "print(f\"Model accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Forests can provide feature importance scores. Let's visualize these to understand which features are most influential in our model's decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "importances = rf_classifier.feature_importances_\n",
        "feature_names = [f'Feature {i}' for i in range(X.shape[1])]\n",
        "\n",
        "plt.bar(feature_names, importances)\n",
        "plt.title('Feature Importances')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This concludes our introduction to Random Forest classifiers using scikit-learn. We've covered creating a model, fitting it to data, making predictions, evaluating accuracy, and examining feature importances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}