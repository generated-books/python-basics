{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87404224-b84b-409f-8683-c4a243d29722",
   "metadata": {},
   "source": [
    "# Generating a Jupyter book about Python basics\n",
    "In this notebook we will generate a Jupyter book using a large language model. We use Claude 3.5 Sonnet, because I couldn't make it work with gpt4-omni :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "752e974d-9aaf-44aa-80fb-01a042cf5774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.30.1', '0.29.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import anthropic\n",
    "import os\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from IPython.display import Markdown, display\n",
    "openai.__version__, anthropic.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944d3a85-c367-41f8-94dd-87e0b4187740",
   "metadata": {},
   "source": [
    "## Defining the content of the book\n",
    "The topic of the book will be specified and also the table of contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de2375a5-d453-4c58-9b31-9baf19914e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"Python basics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf2c99e3-ae03-41d0-b6dd-350181cdd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The table of contents must be a markdown list with * at the beginning of every line.\n",
    "toc = \"\"\"\n",
    "* Introduction to Jupyter notebooks\n",
    "* Mathematical operations\n",
    "* Data Types: Lists, Tuples, Dictionaries\n",
    "* For-loops\n",
    "* Conditional statements\n",
    "* Custom functions\n",
    "* Image Processing with sckit-image\n",
    "* Tabular data wrangling with pandas\n",
    "* Plotting with seaborn\n",
    "* Random forest classifiers in scikit-learn\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07f0b9-9eda-47c2-9e1b-0873930ec5b0",
   "metadata": {},
   "source": [
    "We will also specify the location where to store the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea1686b-9098-429a-b216-121a3f46f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"\"\n",
    "repository_url = \"https://github.com/generated-books/python-basics\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef14a82-c1ac-4367-a83f-067923eae779",
   "metadata": {},
   "source": [
    "We will use this language model to generate the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e3b22c-f57c-41c1-8a13-8049e23b3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"claude-3-5-sonnet-20240620\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6903cd45-0b6b-4090-8597-cc4f644cae38",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "Here we create some helper functions for prompting and for file format handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e686a0f1-9561-426a-b5b8-d222f7966109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_chatGPT(message:str, model=\"gpt-4o-2024-05-13\"):\n",
    "    \"\"\"\n",
    "    A prompt helper function that sends a message to openAI\n",
    "    and returns only the text response.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import openai\n",
    "    \n",
    "    # convert message in the right format if necessary\n",
    "    if isinstance(message, str):\n",
    "        message = [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "    # setup connection to the LLM\n",
    "    client = openai.OpenAI()\n",
    "    \n",
    "    # submit prompt\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=message\n",
    "    )\n",
    "    \n",
    "    # extract answer\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea088a7-f187-4c4e-a269-833e14a957d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_claude(message:str, model=\"claude-3-5-sonnet-20240620\"):\n",
    "    \"\"\"\n",
    "    A prompt helper function that sends a message to anthropic\n",
    "    and returns only the text response.\n",
    "\n",
    "    Example models: claude-3-5-sonnet-20240620 or claude-3-opus-20240229\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from anthropic import Anthropic\n",
    "    \n",
    "    # convert message in the right format if necessary\n",
    "    if isinstance(message, str):\n",
    "        message = [{\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "    # setup connection to the LLM\n",
    "    client = Anthropic()\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        max_tokens=4096,\n",
    "        messages=message,\n",
    "        model=model,\n",
    "    )\n",
    "\n",
    "    # extract answer\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721c3126-67a5-4a65-8bfb-c054bd4dd153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"gpt\" in model:\n",
    "    prompt = partial(prompt_gpt, model=model)\n",
    "else:\n",
    "    prompt = partial(prompt_claude, model=model)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a137f79a-287c-4283-8e66-53c8863cdc86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_with_memory(message:str):\n",
    "    \"\"\"\n",
    "    This function allows to use an LLMs in a chat-mode. \n",
    "    The LLM is equipped with some memory, \n",
    "    so that we can refer back for former conversation steps.\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert message in the right format and store it in memory\n",
    "    question = {\"role\": \"user\", \"content\": message}\n",
    "    chat_history.append(question)\n",
    "    \n",
    "    # receive answer\n",
    "    response = prompt(chat_history)\n",
    "    \n",
    "    # convert answer in the right format and store it in memory\n",
    "    answer = {\"role\": \"assistant\", \"content\": response}\n",
    "    chat_history.append(answer)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c8b27a-77f0-431d-a68c-ee4b19f647b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_json(test_string):\n",
    "    \"\"\"This function returns if a string is formatted json.\"\"\"\n",
    "    import json\n",
    "    try:\n",
    "        json.loads(test_string)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def ensure_json(notebook):\n",
    "    \"\"\"This function makes sure that the passed notebook is indeed a json-formatted ipynb file.\"\"\"\n",
    "    if is_valid_json(notebook):\n",
    "        return notebook\n",
    "        \n",
    "    return prompt(f\"\"\"\n",
    "Take the following text and extract the Jupyter \n",
    "notebook ipynb/json from it:\n",
    "\n",
    "{notebook}\n",
    "\n",
    "Make sure the output is in ipynb/json format. \n",
    "Respond only the JSON content.\n",
    "\"\"\").strip(\"```json\").strip(\"```python\").strip(\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a5b4c-29d7-4ec7-b7e2-f232a695f960",
   "metadata": {},
   "source": [
    "## Context\n",
    "Here we provide some context to the language model. As gpt4 and claude have different APIs for providing system messages, we instead use this message to start the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeab283c-8453-4cd7-a0d8-0583c2bd64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are data scientist and statistician. \n",
    "You have didactic skills and you can explain data analysis very well.\n",
    "You are about to write a Jupyter book consisting of multiple Jupyter notebooks about a given topic.\n",
    "\n",
    "When writing a notebook, always keep the code in the code cells concise. \n",
    "Do only one thing and let the user see the intermediate result.\n",
    "Then, continue with the next thing in a new code cell.\n",
    "\n",
    "Confirm this with \"ok\".\n",
    "\"\"\"\n",
    "\n",
    "chat_history = [{\"role\": \"user\", \"content\": system_message}, {\"role\": \"assistant\", \"content\": \"ok\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c0439-09db-4eb7-b13c-be4d5eb15137",
   "metadata": {},
   "source": [
    "We just test if the chat mode works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c6e8e1-04eb-43b4-b259-b47f6a0907e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Robert Haase! It's a pleasure to meet you. I'm ready to assist you with creating a Jupyter book on data analysis and statistics. As a data scientist and statistician with didactic skills, I'll do my best to explain concepts clearly and provide concise, step-by-step code examples in separate cells. Please let me know what specific topic or area of data analysis you'd like to focus on for this Jupyter book, and I'll be happy to help you get started.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_with_memory(\"Hi, my name is Robert Haase.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3153f9b3-1de7-4e9d-9e63-ded31362680a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Robert Haase.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_with_memory(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80975a9-6422-4158-847a-a77519b8194d",
   "metadata": {},
   "source": [
    "## Chatting about book content\n",
    "We start chatting with the LLM about the book's content. It is key that the LLM _knows_ about all the content of the book before it starts generating the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edefdb37-602d-4864-8ab3-f590bc6c8ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly, Robert. For the topics you've mentioned, several Python libraries will be relevant. Here's a list of the key libraries you'll want to include in your Jupyter book:\n",
       "\n",
       "1. Jupyter: For creating and running the interactive notebooks.\n",
       "\n",
       "2. NumPy: Essential for mathematical operations and working with arrays.\n",
       "\n",
       "3. scikit-image: For image processing tasks.\n",
       "\n",
       "4. pandas: For handling and manipulating tabular data.\n",
       "\n",
       "5. matplotlib: A fundamental plotting library, often used as a backend for other visualization tools.\n",
       "\n",
       "6. seaborn: For statistical data visualization, built on top of matplotlib.\n",
       "\n",
       "7. scikit-learn: For machine learning tasks, including random forest classifiers.\n",
       "\n",
       "8. IPython: For enhanced interactive computing in Python.\n",
       "\n",
       "These libraries will cover the range of topics you've outlined, from basic Python operations to more advanced data analysis and machine learning concepts. They'll provide the necessary tools for demonstrating mathematical operations, data manipulation, visualization, and machine learning techniques in your Jupyter book.\n",
       "\n",
       "Remember, we won't need to import all of these libraries in every notebook, but they'll be important across the various sections of your training material. When we start writing code, we'll import only the libraries needed for each specific lesson or example."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(prompt_with_memory(f\"\"\"\n",
    "I would like to teach others in {topic} and cover these aspects:\n",
    "{toc}\n",
    "\n",
    "Therefore, it would be great to have training material in the form of a Jupyter book.\n",
    "\n",
    "Which Python libraries are relevant in this context? Do not write any Python code yet.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eccf60-0cd3-4600-939a-7b94e00624db",
   "metadata": {},
   "source": [
    "## Generating the book\n",
    "Here we start generating the notebooks for the content listed in the table of contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be6fefdf-c1cc-4ce0-9521-7f8f2b6b3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction to Jupyter notebooks : docs\\01_introduction_to_jupyter_notebooks.ipynb\n",
      "Mathematical operations : docs\\02_mathematical_operations.ipynb\n",
      "Data Types: Lists, Tuples, Dictionaries : docs\\03_data_types_lists_tuples_dictionaries.ipynb\n",
      "For-loops : docs\\04_for_loops.ipynb\n",
      "Conditional statements : docs\\05_conditional_statements.ipynb\n",
      "Custom functions : docs\\06_custom_functions.ipynb\n",
      "Image Processing with sckit-image : docs\\07_image_processing_with_scikit_image.ipynb\n",
      "Tabular data wrangling with pandas : docs\\08_tabular_data_wrangling_with_pandas.ipynb\n",
      "Plotting with seaborn : docs\\09_plotting_with_seaborn.ipynb\n",
      "Random forest classifiers in scikit-learn : docs\\10_random_forest_classifiers_scikit_learn.ipynb\n"
     ]
    }
   ],
   "source": [
    "contents = toc.strip(\"\\n\").strip(\"* \").split(\"\\n* \")\n",
    "\n",
    "for i, subtopic in enumerate(contents):\n",
    "    notebook = ensure_json(prompt(\n",
    "        [{\"role\": \"user\", \"content\": system_message},\n",
    "         {\"role\": \"assistant\", \"content\": \"ok\"},\n",
    "         {\"role\": \"user\", \"content\": f\"\"\"\n",
    "    Please write a Jupyter notebook in json format about \"{subtopic}\" as part of a course about {topic}.\n",
    "    Respond only the JSON content.\n",
    "    \"\"\"}])).strip(\"```json\").strip(\"```python\").strip(\"```\")\n",
    "\n",
    "    # f\"{i:02}_\" + \n",
    "    filename = Path(base_dir) / \"docs\" / prompt_with_memory(f\"What would be a good filename for the '{subtopic}' notebook? Make sure it contains no spaces and ends with .ipynb . Respond with the filename only.\")\n",
    "\n",
    "    directory = directory = Path(filename).parent\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(notebook)\n",
    "\n",
    "    print(subtopic, \":\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e183b86-e01e-4baa-8a1e-388f77875c13",
   "metadata": {},
   "source": [
    "## Generating additional text and config files\n",
    "We would like to build the book automatically, and we also need some introduction texts and documentation. Now that the individual notebooks have been built, we can generate those additional files as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f69c914-e7e4-431d-82dc-a8a6c9c90b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_folder = Path(base_dir) / \"docs\"\n",
    "\n",
    "more_files = {\n",
    "    Path(base_dir) / \"docs\" / \"intro.md\": \n",
    "f\"\"\"\n",
    "Create a intro.md file for a jupyter book that contains all Jupyter notebooks we just created. \n",
    "The introduction should give an overview in text form and with bullet points linking to the notebooks.\n",
    "Mention that the entire book is AI-generated.\n",
    "The repository url of the book is `{repository_url}`.\n",
    "Mention that the `generator.ipynb` file in the github repository contains all the code used for generating the book. Add a link to this file.\n",
    "Respond the content of this file only.\n",
    "\"\"\",\n",
    "    \n",
    "    Path(base_dir) / \"docs\" / \"_toc.yml\": \n",
    "\"\"\"\n",
    "Build a table of contents in Jupytyer book yml format.\n",
    "First, mention the intro.md file.\n",
    "Please give me the list of all notebook filenames we just created. \n",
    "Put them in a _yml file for a Jupyter book.\n",
    "Respond the content of this file only.\n",
    "\"\"\",\n",
    "    \n",
    "    Path(base_dir) / \"docs\" / \"_config.yml\": \n",
    "f\"\"\"\n",
    "Create a minimal config.yml file for the jupyter book.\n",
    "The book will be uploaded to this github repository: {repository_url}\n",
    "Make sure the notebooks will be executed when the book is built.\n",
    "The icon for the book is saved in ../icon.png\n",
    "Respond the content of this file only.\n",
    "\"\"\",\n",
    "    \n",
    "    Path(base_dir) / \".github\" / \"workflows\" / \"book.yml\": \n",
    "f\"\"\"\n",
    "Write a Github workflow file that builds the book and uploads the content to the gh_pages branch.\n",
    "The book is stored in the `{docs_folder}` folder of the respository.\n",
    "Respond the content of this file only.\n",
    "\"\"\",\n",
    "\n",
    "    Path(base_dir) / \"readme.md\": \n",
    "f\"\"\"\n",
    "Create a readme.md file for the jupyter book. \n",
    "Give instructions how to build the book.\n",
    "Mention that the entire book is AI-generated. \n",
    "Mention that the `generator.ipynb` file in the github repository contains all the code used for generating the book.\n",
    "Respond the content of this file only.\n",
    "\"\"\",\n",
    "}\n",
    "\n",
    "for filename, task in more_files.items():\n",
    "    file_content = prompt_with_memory(task)\n",
    "\n",
    "    directory = Path(filename).parent\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(file_content)\n",
    "\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce81eb-5734-4d54-a7f9-801327a8e0b7",
   "metadata": {},
   "source": [
    "## Chat history\n",
    "For documentation purposes, we output the entire chat with the LLM. Note: The notebooks were generated without storing the notebooks in the chat-history because that would make the history too quickly too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab490c-0cf0-4bf2-8266-585c2450d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31ea97f-aad1-474a-b289-c5b606c0c335",
   "metadata": {},
   "source": [
    "This is just an approximation of the number of tokens in the chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d34b72-bc3e-4c2f-bc67-042826128643",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str(chat_history).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7f540-3e34-4cd6-bdae-9fb7ab0a5b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
